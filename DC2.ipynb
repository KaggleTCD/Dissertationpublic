{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello main\n",
      "Hello\n",
      "---------AFTER tag-----------\n",
      "7\n",
      "---------BEFORE tag-----------\n",
      "15\n",
      "{'lid': 'l97', 'relType': 'AFTER', 'eventInstanceID': 'ei2543', 'relatedToEventInstance': 'ei2497'}\n",
      "{'lid': 'l11', 'relType': 'AFTER', 'eventInstanceID': 'ei2473', 'relatedToEventInstance': 'ei2474', 'signalID': 's25'}\n",
      "{'lid': 'l13', 'relType': 'AFTER', 'eventInstanceID': 'ei2476', 'relatedToEventInstance': 'ei2477', 'signalID': 's29'}\n",
      "{'lid': 'l18', 'relType': 'AFTER', 'eventInstanceID': 'ei2480', 'relatedToTime': 't138', 'signalID': 's155'}\n",
      "{'lid': 'l24', 'relType': 'AFTER', 'eventInstanceID': 'ei2500', 'relatedToEventInstance': 'ei2501', 'signalID': 's161'}\n",
      "{'lid': 'l29', 'relType': 'AFTER', 'eventInstanceID': 'ei2516', 'relatedToEventInstance': 'ei2517', 'signalID': 's163'}\n",
      "{'lid': 'l35', 'relType': 'AFTER', 'eventInstanceID': 'ei2526', 'relatedToEventInstance': 'ei2527', 'signalID': 's97'}\n",
      "Iconicity followed for  e2447  and  e56\n",
      "Iconicity followed for  e24  and  e26\n",
      "Iconicity followed for  e28  and  e30\n",
      "Iconicity followed for  e33  and  t138\n",
      "Iconicity followed for  e64  and  e160\n",
      "Iconicity followed for  e87  and  e88\n",
      "Iconicity followed for  e166  and  e96\n",
      "Sentiment(polarity=0.14285714285714285, subjectivity=0.26785714285714285)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyterlab/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import xml.etree.ElementTree as ET\n",
    "from textblob import TextBlob\n",
    "tokens = []\n",
    "class Iconicity:\n",
    "    def checkIconicity(self,filename,temporalElement):\n",
    "        print(\"Hello\")\n",
    "        f = open(\"count.txt\", \"a\")\n",
    "        \n",
    "        with open (filename) as fin:\n",
    "          tokens = word_tokenize(fin.read())\n",
    "          #print(tokens)\n",
    "          print(\"---------AFTER tag-----------\")\n",
    "          print(tokens.count(\"AFTER\"))\n",
    "          print(\"---------BEFORE tag-----------\")\n",
    "          print(tokens.count(\"BEFORE\"))\n",
    "        mytree = ET.parse(filename)\n",
    "        myroot = mytree.getroot()\n",
    "        dictforTlink = {}\n",
    "        for tags in range(len(myroot)):\n",
    "            if myroot[tags].tag == 'TLINK':\n",
    "                if myroot[tags].attrib['relType']==temporalElement:\n",
    "                    print(myroot[tags].attrib)\n",
    "                    dictforTlink[myroot[tags].attrib['eventInstanceID'] if 'eventInstanceID' in myroot[tags].attrib.keys() else myroot[tags].attrib['timeID']] = myroot[tags].attrib['relatedToTime'] if 'relatedToTime' in myroot[tags].attrib.keys() else myroot[tags].attrib['relatedToEventInstance']\n",
    "        dictforTlink\n",
    "        dictformakeinstance = {}\n",
    "        for tags in range(len(myroot)):\n",
    "            if myroot[tags].tag == 'MAKEINSTANCE':\n",
    "                dictformakeinstance[myroot[tags].attrib['eiid']] = myroot[tags].attrib['eventID']\n",
    "        dictformakeinstance\n",
    "        dictresolved = {}\n",
    "        for x in dictforTlink.keys():\n",
    "            value = dictforTlink[x]\n",
    "            dictresolved[x if 't' in x else dictformakeinstance[x]] = value if 't' in value else dictformakeinstance[value]\n",
    "            \n",
    "        dictresolved\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(filename)\n",
    "        f.write(\"\\n\")\n",
    "        f.write(temporalElement)\n",
    "        f.write(\"\\n\")\n",
    "        followed = 0\n",
    "        notfollowed = 0\n",
    "        for events in dictresolved.keys():\n",
    "            value = dictresolved[events]\n",
    "            if tokens.index(events) > tokens.index(value):\n",
    "                print(\"Iconicity followed for \",events,\" and \",value)\n",
    "                if(\"t\" not in events and \"t\" not in value):\n",
    "                    f.write(\"Iconicity followed\")\n",
    "                    followed = followed+1\n",
    "                    f.write(\"\\n\")\n",
    "                \n",
    "                #print(events,\" has position\",tokens.index(events),\" and \",value,\" has position \",tokens.index(value))\n",
    "            else:\n",
    "                 print(\"Iconicity not followed for \",events,\" and \",value)\n",
    "                 #print(events,\" has position\",tokens.index(events),\" and \",value,\" has position \",tokens.index(value))\n",
    "                 if(\"t\" not in events and \"t\" not in value):\n",
    "                     f.write(\"Iconicity not followed\")\n",
    "                     notfollowed = notfollowed+1\n",
    "                     f.write(\"\\n\")\n",
    "                 \n",
    "        f.write(\"Followed\\n\")\n",
    "        f.write(str(followed/(followed+notfollowed)))\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"Not Followed\\n\")\n",
    "        f.write(str(notfollowed/(followed+notfollowed)))\n",
    "        f.close();\n",
    "    def checkIconicityAfter(self,filename,temporalElement):\n",
    "          print(\"Hello\")\n",
    "          f = open(\"count.txt\", \"a\")\n",
    "        \n",
    "          with open (filename) as fin:\n",
    "            tokens = word_tokenize(fin.read())\n",
    "            #print(tokens)\n",
    "            print(\"---------AFTER tag-----------\")\n",
    "            print(tokens.count(\"AFTER\"))\n",
    "            print(\"---------BEFORE tag-----------\")\n",
    "            print(tokens.count(\"BEFORE\"))\n",
    "          mytree = ET.parse(filename)\n",
    "          myroot = mytree.getroot()\n",
    "          dictforTlink = {}\n",
    "          for tags in range(len(myroot)):\n",
    "              if myroot[tags].tag == 'TLINK':\n",
    "                  if myroot[tags].attrib['relType']==temporalElement:\n",
    "                      print(myroot[tags].attrib)\n",
    "                      dictforTlink[myroot[tags].attrib['eventInstanceID'] if 'eventInstanceID' in myroot[tags].attrib.keys() else myroot[tags].attrib['timeID']] = myroot[tags].attrib['relatedToTime'] if 'relatedToTime' in myroot[tags].attrib.keys() else myroot[tags].attrib['relatedToEventInstance']\n",
    "          dictforTlink\n",
    "          dictformakeinstance = {}\n",
    "          for tags in range(len(myroot)):\n",
    "              if myroot[tags].tag == 'MAKEINSTANCE':\n",
    "                  dictformakeinstance[myroot[tags].attrib['eiid']] = myroot[tags].attrib['eventID']\n",
    "          dictformakeinstance\n",
    "          dictresolved = {}\n",
    "          for x in dictforTlink.keys():\n",
    "              value = dictforTlink[x]\n",
    "              dictresolved[x if 't' in x else dictformakeinstance[x]] = value if 't' in value else dictformakeinstance[value]\n",
    "            \n",
    "          dictresolved\n",
    "          f.write(\"\\n\")\n",
    "          f.write(\"\\n\")\n",
    "          f.write(filename)\n",
    "          f.write(\"\\n\")\n",
    "          f.write(temporalElement)\n",
    "          f.write(\"\\n\")\n",
    "          followed = 0\n",
    "          notfollowed = 0\n",
    "          for events in dictresolved.keys():\n",
    "              value = dictresolved[events]\n",
    "              if tokens.index(events) > tokens.index(value):\n",
    "                  print(\"Iconicity followed for \",events,\" and \",value)\n",
    "                  if(\"t\" not in events and \"t\" not in value):\n",
    "                     f.write(\"Iconicity followed\")\n",
    "                     followed = followed+1\n",
    "                     f.write(\"\\n\")\n",
    "                \n",
    "                 #print(events,\" has position\",tokens.index(events),\" and \",value,\" has position \",tokens.index(value))\n",
    "              else:\n",
    "                   print(\"Iconicity not followed for \",events,\" and \",value)\n",
    "                   #print(events,\" has position\",tokens.index(events),\" and \",value,\" has position \",tokens.index(value))\n",
    "                   if(\"t\" not in events and \"t\" not in value):\n",
    "                      f.write(\"Iconicity not followed\")\n",
    "                      notfollowed = notfollowed+1\n",
    "                      f.write(\"\\n\")\n",
    "                 \n",
    "          f.write(\"Followed\\n\")\n",
    "          f.write(str(followed/(followed+notfollowed)))\n",
    "          f.write(\"\\n\")\n",
    "          f.write(\"Not Followed\\n\")\n",
    "          f.write(str(notfollowed/(followed+notfollowed)))\n",
    "          f.close();\n",
    "            \n",
    "    def sentimentAnalysis(self,text):\n",
    "        return TextBlob(text).sentiment\n",
    "            \n",
    "    def main():\n",
    "      i = Iconicity()\n",
    "      print(\"Hello main\")\n",
    "      i.checkIconicity(\"ABC.tml\",\"BEFORE\")\n",
    "      i.checkIconicityAfter(\"ABC.tml\",\"AFTER\")\n",
    "      i.checkIconicity(\"ABC1.tml\",\"BEFORE\")\n",
    "      i.checkIconicityAfter(\"ABC1.tml\",\"AFTER\")\n",
    "      i.checkIconicity(\"ABC2.tml\",\"BEFORE\")\n",
    "      i.checkIconicityAfter(\"ABC2.tml\",\"AFTER\")\n",
    "      i.checkIconicity(\"ABC3.tml\",\"BEFORE\")\n",
    "      i.checkIconicityAfter(\"ABC3.tml\",\"AFTER\")\n",
    "      i.checkIconicity(\"AP.tml\",\"BEFORE\")\n",
    "      i.checkIconicityAfter(\"AP.tml\",\"AFTER\")\n",
    "      i.checkIconicity(\"AP1.tml\",\"BEFORE\")\n",
    "      i.checkIconicityAfter(\"AP1.tml\",\"AFTER\")\n",
    "      i.checkIconicity(\"APW.tml\",\"BEFORE\")\n",
    "      i.checkIconicityAfter(\"APW.tml\",\"AFTER\")\n",
    "      #i.checkIconicity(\"APW1.tml\",\"BEFORE\") # Only time comparison is here\n",
    "      i.checkIconicityAfter(\"APW1.tml\",\"AFTER\")\n",
    "      i.checkIconicity(\"APW2.tml\",\"BEFORE\")\n",
    "      i.checkIconicityAfter(\"APW2.tml\",\"AFTER\")\n",
    "      i.checkIconicity(\"APW3.tml\",\"BEFORE\")\n",
    "      i.checkIconicityAfter(\"APW3.tml\",\"AFTER\")\n",
    "      i.checkIconicity(\"NYT.tml\",\"BEFORE\")\n",
    "      i.checkIconicityAfter(\"NYT.tml\",\"AFTER\")\n",
    "      i.checkIconicity(\"wsj.tml\",\"BEFORE\")\n",
    "      i.checkIconicityAfter(\"wsj.tml\",\"AFTER\")\n",
    "      i.checkIconicity(\"wsj1.tml\",\"BEFORE\")\n",
    "      i.checkIconicityAfter(\"wsj1.tml\",\"AFTER\")\n",
    "      i.checkIconicity(\"APW4.tml\",\"BEFORE\")\n",
    "      i.checkIconicityAfter(\"APW4.tml\",\"AFTER\")\n",
    "      blob = i.sentimentAnalysis(\"Both US and British officials filed objections to the court's jurisdiction in 1995 claiming Security Council resolutions imposed on Lybia to force the suspects' extradition overruled a Convention which gives Libya the right to try the men\")\n",
    "      print(blob)\n",
    "      #i.checkIconicity(\"ABC.tml\",\"AFTER\")\n",
    "    if __name__ == \"__main__\":\n",
    "      main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 10.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click (from nltk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl (82kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 7.6MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting joblib (from nltk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/a6/d1a816b89aa1e9e96bcb298eb1ee1854f21662ebc6d55ffa3d7b3b50122b/joblib-0.15.1-py3-none-any.whl (298kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 9.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex (from nltk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/a1/6d8fdf4a20ffbbf2bd6003dff47a0628b9e6a4b840c421b0dec27da9376e/regex-2020.6.8-cp36-cp36m-manylinux2010_x86_64.whl (660kB)\n",
      "\u001b[K     |████████████████████████████████| 665kB 29.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm (from nltk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/76/4697ce203a3d42b2ead61127b35e5fcc26bba9a35c03b32a2bd342a4c869/tqdm-4.46.1-py2.py3-none-any.whl (63kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 21.9MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyterlab/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "Successfully built nltk\n",
      "Installing collected packages: click, joblib, regex, tqdm, nltk\n",
      "Successfully installed click-7.1.2 joblib-0.15.1 nltk-3.5 regex-2020.6.8 tqdm-4.46.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting TextBlob\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/f0/1d9bfcc8ee6b83472ec571406bd0dd51c0e6330ff1a51b2d29861d389e85/textblob-0.15.3-py2.py3-none-any.whl (636kB)\n",
      "\u001b[K     |████████████████████████████████| 645kB 8.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from TextBlob) (3.5)\n",
      "Requirement already satisfied: click in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from nltk>=3.1->TextBlob) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from nltk>=3.1->TextBlob) (4.46.1)\n",
      "Requirement already satisfied: regex in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from nltk>=3.1->TextBlob) (2020.6.8)\n",
      "Requirement already satisfied: joblib in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from nltk>=3.1->TextBlob) (0.15.1)\n",
      "Installing collected packages: TextBlob\n",
      "Successfully installed TextBlob-0.15.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install TextBlob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
